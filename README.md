
# ğŸ“˜ Projet Portfolio â€“ Mapping ERP Infor M3 vers Datahub Finance/Achats

**Projet de dÃ©monstration** : Pipeline de donnÃ©es Finance/Achats pour l'intÃ©gration des donnÃ©es Account Payables d'un systÃ¨me ERP Infor M3 vers un Datahub d'entreprise.

> ğŸ¯ **Objectif** : Valoriser mes compÃ©tences en Data Engineering et Analytics Engineering dans un contexte professionnel.

## ğŸ¢ Contexte mÃ©tier simulÃ©

Ce projet reproduit un **scÃ©nario rÃ©aliste** : une entreprise utilise lâ€™ERP **Infor M3** pour gÃ©rer ses achats et finances. Elle souhaite consolider ses donnÃ©es dans un **Datahub** pour :
- Fiabiliser le suivi de ses comptes fournisseurs
- Analyser ses dÃ©lais de paiement
- Produire un P&L multi-entitÃ©

Le rÃ´le du data engineer est de **retrouver les bonnes donnÃ©es dans les tables M3**, les **stocker dans une base de staging**, puis les **valider et prÃ©parer pour analyse**.

## ğŸ“ Objectifs pÃ©dagogiques et techniques

Ce projet illustre ma maÃ®trise des concepts clÃ©s du Data Engineering :
- ğŸ“¥ **Pipeline ELT** : Extraction, chargement et transformation de donnÃ©es ERP
- âœ… **QualitÃ© des donnÃ©es** : Tests automatisÃ©s avec pytest
- ğŸ§± **ModÃ©lisation dimensionnelle** : Conception d'un modÃ¨le staging vers datawarehouse
- ğŸ§ª **Tests unitaires** et reproductibilitÃ©
- ğŸ“Š **PrÃ©paration analytique** : donnÃ©es Gold, KPIs, P&L

## ğŸ—‚ï¸ Architecture technique

```
MAPPING-INFOR-M3/
â”œâ”€â”€ src/                     # ğŸ Code Python
â”‚   â”œâ”€â”€ connection/          # Gestion des connexions DB
â”‚   â”œâ”€â”€ extract/             # Extraction depuis sources
â”‚   â””â”€â”€ load/                # Chargement en staging
â”œâ”€â”€ database/                # ğŸ“Š ModÃ©lisation
â”‚   â”œâ”€â”€ staging/             # Tables de staging
â”‚   â””â”€â”€ dimensions/          # ModÃ¨les dimensionnels (en cours)
â”œâ”€â”€ tests/                   # âœ… Tests qualitÃ© donnÃ©es
â”œâ”€â”€ notebooks/               # ğŸ“ˆ EDA et analyses
â”œâ”€â”€ docs/                    # ğŸ“– Documentation technique
â””â”€â”€ raw_data/                # ğŸ“ DonnÃ©es d'exemple
```

## ğŸ”„ Pipeline implÃ©mentÃ©
![Code ELT](images/pipeline_code.jpg)
### 1. Extraction des donnÃ©es
Simulation de donnÃ©es Account Payables avec les champs :
- `invoice_id`, `supplier_id`, `amount`, `invoice_date`, `due_date`

### 2. Chargement en staging
![DonnÃ©es chargÃ©es](images/database_result.jpg)
- Table `staging.stg_account_payables` 
- Utilisation de SQLAlchemy pour la portabilitÃ©
- Gestion automatique de la crÃ©ation des tables

### 3. ContrÃ´les qualitÃ© (pytest)
![Tests automatisÃ©s](images/tests_results.jpg)
```python
# Exemples de tests implÃ©mentÃ©s
def test_no_null_values():
    # VÃ©rification des colonnes obligatoires

def test_positive_amounts():
    # ContrÃ´le mÃ©tier sur les montants

def test_date_consistency():
    # Logique des dates (due_date >= invoice_date)
```

### 4. Analyse exploratoire
Notebook Jupyter avec :
- Profiling des donnÃ©es (statistiques, distributions)
- DÃ©tection d'anomalies et valeurs aberrantes
- Visualisations mÃ©tier (dÃ©lais de paiement, rÃ©partitions)

## ğŸ’¡ CompÃ©tences dÃ©montrÃ©es

**Data Engineering**
- Pipeline ELT avec Python/Pandas/SQLAlchemy
- Tests automatisÃ©s de qualitÃ© des donnÃ©es
- Gestion des environnements et reproductibilitÃ©

**Analytics Engineering**
- ModÃ©lisation de donnÃ©es Finance (staging/dimensions)
- Documentation technique et mÃ©tier
- Analyse exploratoire et data profiling

**Bonnes pratiques**
- Versioning Git avec structure projet claire
- Configuration par variables d'environnement
- Tests unitaires et intÃ©gration continue

## âš™ï¸ Technologies utilisÃ©es

```python
# Stack technique
- Python 3.9+ (pandas, sqlalchemy, pytest)
- SQL Server / PostgreSQL (adaptable)
- Jupyter Notebooks
- Git/GitHub pour versioning
- Visual Studio Code : dÃ©veloppement Python, gestion de projet
- Extension Database Client (VS Code) : exploration et requÃªtage SQL (SQL Server)
- Git Bash : exÃ©cution des commandes Git et scripts

```

## ğŸš€ Ã‰volutions prÃ©vues

- [ ] **Extension pÃ©rimÃ¨tre** : Account Receivables, General Ledger
- [ ] **Orchestration** : IntÃ©gration Airflow/Prefect
- [ ] **Data Quality** : ImplÃ©mentation Great Expectations
- [ ] **Visualisation** : Dashboards avec Streamlit/Dash
- [ ] **Cloud** : DÃ©ploiement AWS/Azure avec Terraform

## ğŸ“Š RÃ©sultats obtenus

- âœ… Pipeline fonctionnel de bout en bout
- âœ… 95%+ de couverture des tests qualitÃ©
- âœ… Documentation technique complÃ¨te
- âœ… Code maintenable et extensible

## ğŸ” DÃ©monstration

```bash
# Installation et test rapide
git clone https://github.com/LouspDan/Mapping-Infor-M3
cd mapping-infor-m3
pip install -r requirements.txt
make test  # ExÃ©cution des tests qualitÃ©
```

## ğŸ’¼ Valeur ajoutÃ©e pour l'entreprise

Ce projet dÃ©montre ma capacitÃ© Ã  :
- **Industrialiser** des processus de donnÃ©es Finance/Achats
- **Garantir la qualitÃ©** par des tests automatisÃ©s
- **Documenter** pour faciliter la maintenance
- **Ã‰voluer** vers des architectures plus complexes

---

*Projet dÃ©veloppÃ© en autonomie - Disponible pour Ã©changes techniques et dÃ©monstrations*

**Contact** : [LinkedIn](https://linkedin.com/in/esaie-lupepele) | [Email](mailto:esaie.lupepele@gmail.com)

---

**ğŸ›¡ï¸ Clause de confidentialitÃ©**

Ce projet a Ã©tÃ© conÃ§u Ã  des fins pÃ©dagogiques et de dÃ©monstration. Les donnÃ©es, structures et scÃ©narios prÃ©sentÃ©s sont entiÃ¨rement simulÃ©s. Toute ressemblance avec des systÃ¨mes ou entreprises rÃ©els serait purement fortuite
